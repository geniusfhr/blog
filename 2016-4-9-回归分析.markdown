---
layout: post
title:  "统计模型及其matlab实现"
date:   2016-4-9 
author: 方浩然
header-img: "img/post-bg-theory.jpg"
---


建模的方法有两种：

1. 机理驱动 从数据内部的规律入手，从内向外分析数据产生的原因，从而建立模型和预测
2. 数据驱动 从数据本身入手，利用拟合工具来对数据进行整理和分析，建模和预测

很显然，机理驱动对建模者的要求很高，需要理解数据产生的规律，根据背后的机理来建立相关模型。如果没有丰富的知识背景，很难达到目的。所以数据驱动是最常见的建模方法。我们利用数据本身进行统计分析，科学大胆地建立模型，预测数据。

#  温度对产量的影响
第一道题，考查温度x对产量y的影响，得到一组x和y的数据。让我们建立线性回归方程，并检验。所以可以直接使用matlab中regress函数。  
matlab代码如下:

```
x = 20:5:65;
X = [ones(10,1) x'];
Y = [13.2 15.1 16.4 17.1 17.9 18.7 19.6 21.2 22.5 24.3]';

% 一元线性回归 regress
[b,bint,r,rint,stats] = regress(Y,X);
rcoplot(r,rint);
% 点预测
predict_42_by_regress = b(1) + b(2)*42;

%一次多项式拟合  区间预测
Y = Y';
[p,S] = polyfit(x,Y,1);
%多项式的点预测
predict_42_by_polyval = polyval(p,42);
% 多项式的区间预测
[predict_42_by_polyconf,delta] = polyconf(p,42,S);
% 多项式工具 包括绘图 区间预测
polytool(x,Y,1);

```

首先通过regress进行线性回归。根据regress的参数要求，我们构建一个包含ones列的矩阵，这样在自变量和回归系数相乘的时候可以巧妙地带上常数项。


* `regress`返回`[b,bint,r,rint,stats]`,分别表示回归系数，系数区间，残差，残差置信区间，统计量（依次包含R平方，F统计量及出错概率（缺省0.05））。
*  `rcoplot(r,rint)`传入残差和残差的置信区间，可以做出残差图。
得到结果如下：

```
b =
    9.1212
    0.2230

stats =
    0.9821  439.8311    0.0000    0.2333

```

在残差图的分析中，我们未看见异常点。stats统计量中，R平方接近1，F对应的概率p<0.05，于是可以确定该线性模型符合要求。

```
y = 9.1212 + 0.2230 * x

```

### 点预测和区间预测
预测当x = 42 时，y的值。可以直接带入线性模型，得到y的值为`18.4885`。
题意明确要求出y的置信区间。也就是要能够区间预测，regress似乎不能直接实现。于是我们使用`polyfit`进行多项式拟合，间接得到区间预测的值。

- [p,S] = polyfit(x,Y,1); 传入x y数组和最高次数，这里因为我们要进行线性回归，所以次数为1。返回按降幂排列的多项式系数和一个关于误差的结构数据。
- polyval(p,42) p是由polyfit拿到的系数，42是要求的x值。这一步也是点预测。和regress得到的线性模型一致，代入的结果也相同。
- [predict_42_by_polyconf,delta] = polyconf(p,42,S); 可以进行区间预测，返回点预测的结果和相应区间，delta为点预测上下浮动的区间。
- polytool(x,Y,1); 是一个综合性工具，产生一个交互式的界面，综合了conf，fit，和val。很方便。

得到系数p以后，就可以进行多项式求值以及预测了。最终我们得到delta的值为`1.1681`.  
所以可以说 在x = 42时，置信水平为0.95的情况下，y的值为 `【18.4885 - 1.1681 , 18.4885 + 1.1681】`.
至此，第一题完成。

# 耗电分析
家庭耗电量y和两个变量有关，空调使用时间x1和烘干器使用次数x2。研究这三者之间的关系，首先我们建立多元线性回归模型，使用regress线性拟合。
并分析模型的显著性。
matlab代码如下

```
y = [35 63 66 17 94 79 93 66 94 82 78 65 77 75 62 85 43 57 33 65 33]'  ;
x1 = [1.5 4.5 5.0 2.0 8.5 6.0 13.5 8.0 12.5 7.5 6.5 8.0  7.5 8.0 7.5 12.0 6.0 2.5 5.0  7.5 6.0]' ;
x2 = [1 2 2 0 3 3 1 1 1 2 3 1 2 2 1 1 0 3 0 1 0]' ;
X=[ones(21,1) x1 x2] ;
[b,bint,r,rint,stats]=regress(y,X)
% 画出残差图
rcoplot(r,rint);
```

得到数据如下:

```
b =
    8.1054
    5.4659
   13.2166

bint =
    2.8933   13.3175
    4.8761    6.0557
   11.4177   15.0154

```

我们分析残差的置信区间（残差图更直观），发现最后一组数据的区间没有包括零点，也就是说不可能落在回归直线上，于是推测最后一组数据异常，在回归分析中，需要删除该组数据。

```
y(21,:) = [];
x1(21,:) = [];
x2(21,:) = [];

```
于是再进行regress分析，得到结果：

```
b =
    9.7966
    5.4160
   12.5843

bint =
    4.9528   14.6404
    4.8912    5.9409
   10.8997   14.2690

stats =
    0.9759  343.8765    0.0000   12.0793

```

在删除异常数据后，所得模型的stats统计量中，r平方为0.9759，接近1，p = 0远小于0.05，于是我们可以说该线性模型显著性良好。
在置信水平为0.95的情况下，所得多元线性模型为：

```
y = 9.7966 +  5.4160 * x1 + 12.5843 * x2;

```

题意让我们考虑引入非线性项（平方项和交叉项）建立模型。
可以仍然可以转化成线性回归。

```
X=[ones(21,1) x1 x2 (x1.^2) (x2.^2) (x1.*x2)]
```
得到如下结果:
```
b =
    9.4789
    4.5563
   19.9128
    0.0129
   -2.7739
    0.3136
stats =
    0.9839  182.8232    0.0000   10.3093
```

由于p = 0 < 0.05，R^2 = 0.9839 ，模型如下

```
    y = 9.4789 + 4.5563*x1 + 19.9128*x2 + 0.0129*x1^2 - 2.7739*x2^2 + 0.3136*x1*x2

```

我们在残差图中发现有异常数据，删除后重新建立模型，仍然有异常数据。反复如此，于是我们考虑逐步回归，确定引入非线性变量的必要性。
使用stepwise(X,y)，利用matlab中逐步回归工具箱,根据F和MSE的大小，确定变量的必要性。最后发现，删去x1^2变量和x1*x2项后F的值显著提高，RMSE的值降低，于是我们分析得到删去这两个非线性项后模型显著性提高，于是建立新的模型。
仍然，我们将它化成线性使用regress回归。

仍然通过残差图分析，我们两次删去异常数据后发现模型的显著性非常好，数据如下:

```
b =

    5.2913
    5.0918
   24.2141
   -3.4016
bint =
    1.5879    8.9947
    4.6669    5.5166
   19.5268   28.9013
   -4.8329   -1.9702

stats =
    0.9892  459.7563    0.0000    6.4484

```

p远小于0.05，于是我们可以得出该模型显著性良好。

```
y = 5.2913 + 5.0918*x1 + 24.2141*x2  - 3.4016*x2^2 ;

```
